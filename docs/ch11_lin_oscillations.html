<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Mathematical Methods for Biology, Part 1 - 11&nbsp; Forces and potentials in biological modeling</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./ch10_phase_portraits.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Forces and potentials in biological modeling</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Mathematical Methods for Biology, Part 1</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch1_discrete1var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">One variable in discrete time</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch2_plotting_python.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Plotting in Python</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch3_discrete_chaos.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Nonlinear discrete-time dynamic models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch4_cobweb_plots.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Graphical analysis of difference equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch5_discrete_higher.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discrete models of higher order</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch6_matrix_mult.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Matrix multiplication and population models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch7_1var_ode.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Models with one variable in continuous time</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch8_numeric_ode.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Numeric solutions of ODEs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch9_linear_pplane.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Linear ODEs with two variables</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch10_phase_portraits.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Phase portraits in Python</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch11_lin_oscillations.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Forces and potentials in biological modeling</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#forces-and-simple-springs" id="toc-forces-and-simple-springs" class="nav-link active" data-scroll-target="#forces-and-simple-springs"><span class="toc-section-number">11.1</span>  Forces and simple springs</a>
  <ul class="collapse">
  <li><a href="#exponential-growth-and-decay" id="toc-exponential-growth-and-decay" class="nav-link" data-scroll-target="#exponential-growth-and-decay"><span class="toc-section-number">11.1.1</span>  exponential growth and decay</a></li>
  <li><a href="#properties-of-linear-oscillations" id="toc-properties-of-linear-oscillations" class="nav-link" data-scroll-target="#properties-of-linear-oscillations"><span class="toc-section-number">11.1.2</span>  properties of linear oscillations</a></li>
  <li><a href="#potentials-and-forces" id="toc-potentials-and-forces" class="nav-link" data-scroll-target="#potentials-and-forces"><span class="toc-section-number">11.1.3</span>  potentials and forces</a></li>
  <li><a href="#harmonic-spring-potential" id="toc-harmonic-spring-potential" class="nav-link" data-scroll-target="#harmonic-spring-potential"><span class="toc-section-number">11.1.4</span>  harmonic spring potential</a></li>
  <li><a href="#two-masses-connected-by-a-spring" id="toc-two-masses-connected-by-a-spring" class="nav-link" data-scroll-target="#two-masses-connected-by-a-spring"><span class="toc-section-number">11.1.5</span>  two masses connected by a spring</a></li>
  <li><a href="#converting-second-order-odes-into-first-order" id="toc-converting-second-order-odes-into-first-order" class="nav-link" data-scroll-target="#converting-second-order-odes-into-first-order"><span class="toc-section-number">11.1.6</span>  converting second order ODEs into first order</a></li>
  <li><a href="#dynamic-behaviors-of-the-harmonic-oscillator" id="toc-dynamic-behaviors-of-the-harmonic-oscillator" class="nav-link" data-scroll-target="#dynamic-behaviors-of-the-harmonic-oscillator"><span class="toc-section-number">11.1.7</span>  dynamic behaviors of the harmonic oscillator</a></li>
  <li><a href="#forcing-and-inhomogeneous-odes" id="toc-forcing-and-inhomogeneous-odes" class="nav-link" data-scroll-target="#forcing-and-inhomogeneous-odes"><span class="toc-section-number">11.1.8</span>  forcing and inhomogeneous ODEs</a></li>
  <li><a href="#forced-oscillations-and-resonance" id="toc-forced-oscillations-and-resonance" class="nav-link" data-scroll-target="#forced-oscillations-and-resonance"><span class="toc-section-number">11.1.9</span>  forced oscillations and resonance</a></li>
  </ul></li>
  <li><a href="#linearity-and-vector-spaces" id="toc-linearity-and-vector-spaces" class="nav-link" data-scroll-target="#linearity-and-vector-spaces"><span class="toc-section-number">11.2</span>  Linearity and vector spaces</a>
  <ul class="collapse">
  <li><a href="#inner-product-and-orthogonality" id="toc-inner-product-and-orthogonality" class="nav-link" data-scroll-target="#inner-product-and-orthogonality"><span class="toc-section-number">11.2.1</span>  inner product and orthogonality</a></li>
  <li><a href="#projection-and-decomposition" id="toc-projection-and-decomposition" class="nav-link" data-scroll-target="#projection-and-decomposition"><span class="toc-section-number">11.2.2</span>  projection and decomposition</a></li>
  <li><a href="#general-solution-of-linear-odes" id="toc-general-solution-of-linear-odes" class="nav-link" data-scroll-target="#general-solution-of-linear-odes"><span class="toc-section-number">11.2.3</span>  general solution of linear ODEs</a></li>
  </ul></li>
  <li><a href="#computational-normal-mode-calculations" id="toc-computational-normal-mode-calculations" class="nav-link" data-scroll-target="#computational-normal-mode-calculations"><span class="toc-section-number">11.3</span>  Computational: normal mode calculations</a>
  <ul class="collapse">
  <li><a href="#harmonic-analysis-of-coupled-oscillators" id="toc-harmonic-analysis-of-coupled-oscillators" class="nav-link" data-scroll-target="#harmonic-analysis-of-coupled-oscillators"><span class="toc-section-number">11.3.1</span>  harmonic analysis of coupled oscillators</a></li>
  <li><a href="#normal-mode-calculations" id="toc-normal-mode-calculations" class="nav-link" data-scroll-target="#normal-mode-calculations"><span class="toc-section-number">11.3.2</span>  normal mode calculations</a></li>
  </ul></li>
  <li><a href="#normal-mode-analysis-of-biomolecular-structures" id="toc-normal-mode-analysis-of-biomolecular-structures" class="nav-link" data-scroll-target="#normal-mode-analysis-of-biomolecular-structures"><span class="toc-section-number">11.4</span>  Normal mode analysis of biomolecular structures</a>
  <ul class="collapse">
  <li><a href="#biomolecular-structures-as-elastic-solids" id="toc-biomolecular-structures-as-elastic-solids" class="nav-link" data-scroll-target="#biomolecular-structures-as-elastic-solids"><span class="toc-section-number">11.4.1</span>  biomolecular structures as elastic solids</a></li>
  <li><a href="#sorting-normal-modes-by-frequency" id="toc-sorting-normal-modes-by-frequency" class="nav-link" data-scroll-target="#sorting-normal-modes-by-frequency"><span class="toc-section-number">11.4.2</span>  sorting normal modes by frequency</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Forces and potentials in biological modeling</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>In the last chapter we learned to analyze the dynamics of linear dynamical systems by finding the eigenvalues of corresponding matrices. In this chapter, we will study a class of mathematical models with a classical physics pedigree. These models are based on a physical potential, which is usually given by a physical law, e.g.&nbsp;gravity. These systems are special, because they have a conserved quantity that is known as energy. We will learn about the consequences of such conserved quantities, and what happens when the conservation is broken and energy dissipates.</p>
<p>The main type of models that we will address are oscillators, with the simplest being simple springs. These models are in fact relevant for biological modeling in a variety of fields. We will apply the analysis to the study of biomolecular flexibility, to predict the preferred directions of internal motion of parts of protein molecules. The study of protein structural dynamics has important implication to understanding the mechanism of function of many biochemical systems. For example, many signaling molecules undergo conformational changes upon binding or phosphorylation, which generates changes in their biochemical actions.</p>
<p>The modeling section explains the basic physics of forces and potential functions. We will use examples of a single mass on a spring, and the scale up to two masses connected by a spring. In the analytic section, we will learn how to turn second order ODEs into first order dynamical systems, then find the explicit solutions for the oscillations of a simple spring. We will show how damping enters the solution, and what effect it has on conservation. We will also learn how to include external forcing in the model. In the computational section we will describe a general system of coupled linear oscillators using normal mode analysis. In the final section normal mode analysis is applied to studying the dynamics of protein structures.</p>
<section id="forces-and-simple-springs" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="forces-and-simple-springs"><span class="header-section-number">11.1</span> Forces and simple springs</h2>
<p>As we have learned in the last two chapters, linear dynamical systems have general solutions in the form of a weighted sum of exponentials:</p>
<p><span class="math display">\[
\vec x(t) = \sum_i c_i \vec v_i e^{\lambda_i t}
\]</span></p>
<p>The type of dynamics possible in a system is determined by the eigenvalues <span class="math inline">\(\lambda_i\)</span> of the corresponding matrix. If they are real, the system will grow or decay exponentially, while the presence of imaginary part produces oscillations, with growing, decaying, or constant amplitude, depending on the real part. Below we describe the modeling situations in which this limited menu of dynamics may be applied.</p>
<section id="exponential-growth-and-decay" class="level3" data-number="11.1.1">
<h3 data-number="11.1.1" class="anchored" data-anchor-id="exponential-growth-and-decay"><span class="header-section-number">11.1.1</span> exponential growth and decay</h3>
<p>No biological systems have purely exponential dynamics, as nothing in nature can realistically grow without bound, or decay inexorably to zero. Nevertheless, exponential behavior can be useful for modeling the dynamics in a limited regime, especially near an equilibrium. We have seen an illustration of this idea in the first part of the course, when we analyzed nonlinear one dimensional dynamical systems by approximating them with a linear system near an equilibrium. This linearization process is also applicable to multidimensional systems, where it involves the use of a first derivative matrix (called the <em>Jacobian</em>) as the local linear approximation. We will learn how to do this in detail in a future chapter, but the idea remains the same: by analyzing the eigenvalues of the matrix, one can predict whether the solution of the system grows or decays near the equilibrium. In the first case, the equilibrium is unstable, in the second, it is stable.</p>
</section>
<section id="properties-of-linear-oscillations" class="level3" data-number="11.1.2">
<h3 data-number="11.1.2" class="anchored" data-anchor-id="properties-of-linear-oscillations"><span class="header-section-number">11.1.2</span> properties of linear oscillations</h3>
<p>Another area of applicability of linear models is for describing oscillatory behavior. Many biological systems exhibit oscillatory dynamics, ranging from heartbeat and circadian rhythms in physiology, to cycles of biochemical reactions and firing of neurons. We know that linear systems with complex eigenvalues have oscillatory dynamics, so it is tempting to describe these phenomena with linear models. As we saw above, however, linear models cannot describe real biological systems over all possible values of its variable. Linear oscillations have specific properties which are generally not found in real systems: if the real part of the eigenvalue is nonzero, they either have exponentially growing or decaying amplitudes, which, as we argued above is not biologically feasible in the long run. This leaves the situation when the real part is zero, and the oscillations have a constant amplitude. This situation is not immediately unrealistic, but it has its own specific limitations: in it, oscillations of all amplitudes are possible, regardless of the frequency (think of the simple harmonic oscillator in the previous chapter.) This is also unrealistic, and nonlinear models are necessary to model the dynamics usually observed in reality, in which oscillations occurs with a preferred frequency and amplitude.</p>
</section>
<section id="potentials-and-forces" class="level3" data-number="11.1.3">
<h3 data-number="11.1.3" class="anchored" data-anchor-id="potentials-and-forces"><span class="header-section-number">11.1.3</span> potentials and forces</h3>
<p>The dynamics of systems in classical physical are defined by their potential functions. The <em>potential energy</em> describes the propensity of the system to do work, that is, to apply <em>force</em> to an object over some distance. By definition, work is the difference between the potentials at the two endpoints of the path, <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. This can be summarized in the following equation, relating <em>work</em> <span class="math inline">\(W\)</span> done on an object by applying force <span class="math inline">\(f(x)\)</span> over the distance from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>:</p>
<p><span class="math display">\[
W = V(b) - V(a) = \int_a^b f(x) dx
\]</span></p>
<p>Intuitively, one can think of a potential function <span class="math inline">\(V(x)\)</span> as a law handed from on high, which dictates what forces are going to act on the system. The forces then make the objects in the systems move, generating dynamics that we care about and will investigate in this chapter.</p>
<p>The above connection between potential and force has a familiar form. In fact, it is equivalent to the Fundamental Theorem of calculus, where we define the force <span class="math inline">\(f(x)\)</span> to be the derivative of the potential <span class="math inline">\(V(x)\)</span>. This relationship is at the center of this chapter:</p>
<p><span class="math display">\[
f(x) = -V'(x)
\]</span></p>
<p>Graphically speaking, the force is the negative slope of the potential function. This means that if the force is always pushing the object down the slope: if the potential is rising, it is pushing backward, and if the potential is falling, it is pushing forward. Essentially, this definition is consistent with the metaphor of potential as a terrain, with gravitational force bringing objects down to the lowest point of the landscape.</p>
</section>
<section id="harmonic-spring-potential" class="level3" data-number="11.1.4">
<h3 data-number="11.1.4" class="anchored" data-anchor-id="harmonic-spring-potential"><span class="header-section-number">11.1.4</span> harmonic spring potential</h3>
<p>We will define a specific potential for a mass on a spring and investigate the resulting dynamical system in the analytical section. The assumptions are: a) that there is a position <span class="math inline">\(x_0\)</span> at which the spring is at rest, that is, no force is acting on the object, and b) that the force will push the object back toward the resting position, with strength proportional to the displacement <span class="math inline">\((x-x_0)\)</span> of the mass from the resting position. Turns out that this model is defined by the following potential function:</p>
<p><span class="math display">\[
V(x) = \frac{1}{2}k(x-x_0)^2
\]</span></p>
<p>Here <span class="math inline">\(k\)</span> is known as the <em>spring constant</em>, and this parameter describes the strength of the restoring force: for large <span class="math inline">\(k\)</span>, the mass will be pulled toward the resting state with greater force than with a smaller <span class="math inline">\(k\)</span>. Notice that the potential has a minimum at <span class="math inline">\(x_0\)</span>, since this is the position that is most favorable for the system. The variables and parameters of the model are illustrated in figure .</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/harmonic_oscillator.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Mass on a spring, with a restoring force <span class="math inline">\(F\)</span> and rest position <span class="math inline">\(x_0\)</span>. <a href="http://openlearn.open.ac.uk/" class="uri">http://openlearn.open.ac.uk/</a></figcaption><p></p>
</figure>
</div>
<p>Using the relationship in equation [eq:force_pot] above, we conclude that the <em>restoring force</em> in the system obeys the following equation:</p>
<p><span class="math display">\[
f(x) = k (x_0-x)
\]</span></p>
<p>This model of a simple spring with a quadratic potential and linear force is called a <em>Hookean</em> spring model, after the physicist Robert Hooke. The idealized linear spring model is also called a <em>harmonic oscillator</em>, because, as we will see in the analytical section, its solutions are perfect periodic oscillations.</p>
<p>The expression for force can be translated into the language of ODEs and dynamics using Newton’s second law, which states that <span class="math inline">\(f = ma\)</span>. Recall that the acceleration in physics is the second derivative of position, and we can write down the dynamical system of a harmonic oscillator as follows:</p>
<p><span class="math display">\[
m\ddot x = k (x_0-x)
\]</span></p>
<p>We will learn to solve this equation in the next section.</p>
<p>In reality, there is usually another force that acts to slow down any moving object. This effect is called <em>kinetic friction</em>, or <em>viscosity</em> if the object is in a fluid, such as air or water. The typical model for kinetic friction assumes the friction force is proportional to the velocity of the object. The relationship has a negative sign, since the force acts in the opposite direction of the velocity, slowing down the motion. The friction force <span class="math inline">\(g(x)\)</span> is defined as follows.</p>
<p><span class="math display">\[
g(x) = - \gamma v = - \gamma \dot x
\]</span></p>
<p>Thus, a system incorporating a harmonic oscillator with friction has the following equation of motion:</p>
<p><span class="math display">\[
m\ddot x = k (x_0-x) - \gamma \dot x
\]</span></p>
</section>
<section id="two-masses-connected-by-a-spring" class="level3" data-number="11.1.5">
<h3 data-number="11.1.5" class="anchored" data-anchor-id="two-masses-connected-by-a-spring"><span class="header-section-number">11.1.5</span> two masses connected by a spring</h3>
<p>We have only looked at a single oscillator, whose dynamics depend solely on its own position. Now, consider two separate objects connected by a linear Hookean spring. Let us define <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> to be the displacements of the two objects from the respective resting positions; this way we don’t have to keep around <span class="math inline">\(x_0\)</span> and <span class="math inline">\(y_0\)</span>. The force depends on the distance between the two of them, and if we restrict the model to one dimension, it depends on the difference between the two displacements. The force on each particle is in the opposite direction of its own displacement and in the same direction as the other particle’s displacement, so the equations are:</p>
<p><span class="math display">\[
\begin{aligned}
m \ddot x &amp;=&amp; -k(x-y) \\
m \ddot y &amp;=&amp; -k(y-x)
\end{aligned}
\]</span></p>
<p>The dynamical system can be expressed in matrix form, where the matrix <span class="math inline">\(A\)</span> is:</p>
<p><span class="math display">\[
A = \frac{k}{m}\left(\begin{array}{cc}-1 &amp; 1 \\1 &amp; -1\end{array}\right)
\]</span></p>
<p>Then the system of ODEs can be written down more concisely, with the vector <span class="math inline">\(\vec x\)</span> contains the positions of both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
\ddot {\vec x} = A \vec x
\]</span></p>
</section>
<section id="converting-second-order-odes-into-first-order" class="level3" data-number="11.1.6">
<h3 data-number="11.1.6" class="anchored" data-anchor-id="converting-second-order-odes-into-first-order"><span class="header-section-number">11.1.6</span> converting second order ODEs into first order</h3>
<p>In the previous section we found the can transform it into a 2D system and use the geometric methods of phase plane analysis analysis. Let us introduce a second variable <span class="math inline">\(y = \dot x\)</span>. Then <span class="math inline">\(\dot y = \ddot x\)</span>, and we can write a system of equations in the standard first order form, which will enable us to use our analytical tools.</p>
<p><strong>Example.</strong> Let us consider the harmonic oscillator with no damping, as defined in the modeling section. The second order equation can be written as two first order equations:</p>
<p><span class="math display">\[
\begin{aligned}
\dot y &amp;=&amp; - \frac{k}{m}x \\
\dot x &amp;=&amp; y
\end{aligned}
\]</span></p>
<p>The eigenvalues of this system are <span class="math inline">\(\lambda = \pm \sqrt\frac{k}{m} i\)</span>, and <span class="math inline">\(\sqrt\frac{k}{m}\)</span> is the frequency of oscillation of this model, which in physics is used to model a simple Hookean spring. The solutions are in the form of sines and cosines, and we can write it:</p>
<p><span class="math display">\[
x(t) = A \cos(\sqrt\frac{k}{m}t) + B \sin(\sqrt\frac{k}{m}t)
\]</span></p>
<p>The constants <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are determined by the initial conditions. Note that for second order equations, two initial conditions must be specified (e.g.&nbsp;one for <span class="math inline">\(x\)</span> and one for <span class="math inline">\(\dot x\)</span>) to determine the two integration constants.</p>
<p><strong>Example.</strong> Let us now consider the harmonic oscillator with damping added. The second order equation can be written as two first order equations: <span class="math display">\[
\begin{aligned}
\dot y &amp;=&amp; - \frac{k}{m}x -\frac{\gamma}{m}y \\
\dot x &amp;=&amp; y
\end{aligned}
\]</span></p>
<p>The eigenvalues of this system are: <span class="math inline">\(\lambda = (-\gamma \pm \sqrt{\gamma^2-4km})/2m\)</span>. This means, depending on the sign of <span class="math inline">\(\gamma^2-4km\)</span>, the eigenvalues may be either real or complex. If they are complex, the solutions will be damped oscillations because the real part (<span class="math inline">\(-\gamma\)</span>) is negative. The solution can be written with the following exponential and oscillation terms:</p>
<p><span class="math display">\[
x(t) = Ae^{-\frac{\gamma}{m} t}\cos[(\sqrt{k/m-\gamma^2/4m^2}) t ]+Be^{-\frac{\gamma}{m} t}\sin[(\sqrt{k/m-\gamma^2/4m^2}) t]
\]</span></p>
</section>
<section id="dynamic-behaviors-of-the-harmonic-oscillator" class="level3" data-number="11.1.7">
<h3 data-number="11.1.7" class="anchored" data-anchor-id="dynamic-behaviors-of-the-harmonic-oscillator"><span class="header-section-number">11.1.7</span> dynamic behaviors of the harmonic oscillator</h3>
<p>We have seen that when there is a restoring force <span class="math inline">\(F = -kx\)</span>, were <span class="math inline">\(x\)</span> is the displacement from a resting value, the differential equation from Newton’s second law is <span class="math inline">\(m \ddot x = - kx\)</span>, or <span class="math inline">\(\ddot x = -\omega^2 x\)</span>, with <span class="math inline">\(\omega = \sqrt{k/m}\)</span>. We can see immediately from this expression that sines and cosines are solutions, because by taking two derivatives one gets back the same function, multiplied by the negative square of the frequency (check this yourself). This is also what we get from eigenvalue analysis, by finding the eigenvalues of the system <span class="math inline">\(\pm \omega i\)</span>.</p>
<p>If there is a nonzero first derivative term in the force, <span class="math inline">\(F = -kx + \gamma \dot x\)</span>; if <span class="math inline">\(\gamma\)</span> is negative it is called a damping term. Let us analyze this scenario by finding the eigenvalues of the corresponding second-order ODE <span class="math inline">\(\ddot x + \gamma/m \dot x + \omega^2 x = 0\)</span>:</p>
<p><span class="math display">\[
\lambda = (-\gamma/m \pm \sqrt{(\gamma/m)^2 - 4\omega^2})/2
\]</span></p>
<p>We see that the eigenvalues are real if <span class="math inline">\((\gamma/m)^2 &gt; 4\omega^2\)</span>, and complex if <span class="math inline">\((\gamma/m)^2 &lt; 4\omega^2\)</span>, and the solutions would be decaying exponentials. Physically speaking, if damping is too strong, the system’s propensity for oscillations is overpowered, and the displacement <span class="math inline">\(x\)</span> never gets to the other side of 0 (think of a mass on a spring in molasses). This system is called <em>overdamped</em>. On the other hand, if <span class="math inline">\(\gamma\)</span> is below the threshold value, oscillations persist, although they tend to zero with time, in the form of <span class="math inline">\(e^{-\gamma/m}(A\sin(\omega t) + B\cos(\omega t))\)</span>. This system is called <em>underdamped</em>. At <span class="math inline">\((\gamma/m)^2 = 4\omega^2\)</span>, the situation is called <em>critical damping</em> - the oscillator will return to its resting state and just miss overshooting it.</p>
<p>If <span class="math inline">\(\gamma\)</span> were positive (I cannot think of a physical or biological example) the situation would be reversed, leading to exponentially growing oscillations or pure exponential growth.</p>
</section>
<section id="forcing-and-inhomogeneous-odes" class="level3" data-number="11.1.8">
<h3 data-number="11.1.8" class="anchored" data-anchor-id="forcing-and-inhomogeneous-odes"><span class="header-section-number">11.1.8</span> forcing and inhomogeneous ODEs</h3>
<p>We will now consider a system that consists of a harmonic oscillator to which which an external force is applied. Mathematically, the force is external if it does not depend on the variables of the system, although it may depend on time.</p>
<p>Now let us consider a harmonic oscillator that is driven by a periodic external force. This could represent a mass on a spring which is being “forced” by an external influence, or an oscillating neuron that receives a periodic signal from another neuron.</p>
<p>We will now consider an inhomogeneous ODE with the <em>method of undetermined coefficients</em>. The rule of thumb is: if the form of the inhomogeneity is unchanged by differentiation (e.g.&nbsp;exponentials, polynomials) then use this form multiplied by some constants as a guess for the particular solution. Then substitute it into the ODE, and find which values of the constants will satisfy the ODE.</p>
<p><span class="math display">\[
\ddot x + \omega_0^2x = C\cos(\omega t)
\]</span></p>
<p>First, the solution of the homogeneous equation is a sum of sines and cosines with frequency <span class="math inline">\(\omega_0\)</span>: <span class="math inline">\(x_h =A \cos(\omega_0t) + B\sin(\omega_0t)\)</span>. To find the particular solution, let us assume that the solution has the same form as the forcing term, with some undetermined coefficients: <span class="math inline">\(x_h = C_1\cos(\omega t) + C_2 \sin(\omega t)\)</span>.</p>
<p>The second derivative is then: <span class="math inline">\(\ddot x_h = -C_1\omega^2\cos(\omega t) -C_2 \omega^2\sin(\omega t)\)</span>. Plugging this into the equation we have:</p>
<p><span class="math display">\[
-C_1\omega^2\cos(\omega t) -C_2 \omega^2\sin(\omega t) +  \omega_0^2( C_1\cos(\omega t) + C_2 \sin(\omega t)) = C\cos(\omega t)
\]</span></p>
<p>Since there is no sine term on the right hand side, we need to set <span class="math inline">\(C_2 = 0\)</span>. The cosine terms yield the following expression: <span class="math inline">\((-C_1\omega^2 + \omega_0^2 C_1)\cos(\omega t) = C\cos(\omega t) \Rightarrow C_1 = C/( \omega_0^2-\omega^2)\)</span>.</p>
<p>Adding the homogeneous and the particular solutions together, we find the general solution for a harmonic oscillator with a periodic driving force: <span class="math display">\[
x(t) = x_h + x_p =  A \cos(\omega_0t) + B\sin(\omega_0t) + \frac{C}{\omega_0^2-\omega^2}\cos(\omega t)
\]</span></p>
<p>The solution is a superposition of oscillations at the inherent frequency of the oscillator (<span class="math inline">\(\omega_0\)</span>) and the external driving frequency (<span class="math inline">\(\omega\)</span>). What happens when the two frequencies match?</p>
</section>
<section id="forced-oscillations-and-resonance" class="level3" data-number="11.1.9">
<h3 data-number="11.1.9" class="anchored" data-anchor-id="forced-oscillations-and-resonance"><span class="header-section-number">11.1.9</span> forced oscillations and resonance</h3>
<p>When <span class="math inline">\(\omega = \omega_0\)</span> he particular solution found above no longer exists because of division by zero. Thus, we need to seek another solution. Let us try the guess of <span class="math inline">\(x_h = C_1t\cos(\omega t) + C_2 t\sin(\omega t)\)</span>. Let us find its derivative, using the product rule: <span class="math inline">\(\dot x_h = C_1\cos(\omega t) - C_1\omega t\sin(\omega t) + C_2 \sin(\omega t) + C_2 \omega t\cos(\omega t)\)</span>. The second derivative then becomes: <span class="math inline">\(\ddot x_h = -C_1 \omega \sin(\omega t) - C_1 \omega \sin(\omega t) - C_1\omega^2 t\cos(\omega t) + C_2 \omega \cos(\omega t) + C_2\omega \cos(\omega t) -C_2\omega^2 t\sin(\omega t)\)</span>. Substituting this into the inhomogeneous ODE, we have:</p>
<p><span class="math display">\[
-2C_1\omega \sin(\omega t) - C_1\omega^2 t\cos(\omega t)+2C_2 \omega \cos(\omega t) -C_2\omega ^2 t\sin(\omega t)  + \omega^2( C_1t\cos(\omega t) + C_2t \sin(\omega t)) = C\cos(\omega t)
\]</span></p>
<p>Let us break this up into equations for the different terms:</p>
<p><span class="math display">\[
\begin{aligned}
-2C_1\omega \sin(\omega t) &amp;=&amp; 0 \\
-2C_2\omega \cos(\omega t) &amp;=&amp; C\cos(\omega t) \\
-C_1\omega^2 t\cos(\omega t) + C_1 \omega^2 t\cos(\omega t) &amp;=&amp; 0 \\
-C_2\omega ^2 t\sin(\omega t) + C_2 \omega^2 t \sin(\omega t) &amp;=&amp; 0
\end{aligned}
\]</span></p>
<p>Note that the latter two are true for any values of the constants. The first one requires that <span class="math inline">\(C_1 = 0\)</span>, and the second one gives <span class="math inline">\(C_2 = -C/2\)</span>. Thus, the particular solution is:</p>
<p><span class="math display">\[
x_p(t) = -\frac{C}{2}t \sin(\omega t)
\]</span></p>
<p>Driving an undamped harmonic oscillator at its natural frequency results in linearly growing, unbounded oscillations. This phenomenon is called <em>resonance</em>, and although no natural system can exhibit unbounded growth in oscillations, resonance is a profound natural phenomenon, resulting in physical effects such as collapses of bridges if an external force (e.g.&nbsp;wind) happens to match its resonant frequency, or in more useful applications, giving us amplification of radio signals by resonant circuits, as well as sophisticated biological mechanisms that we will discuss later.</p>
</section>
</section>
<section id="linearity-and-vector-spaces" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="linearity-and-vector-spaces"><span class="header-section-number">11.2</span> Linearity and vector spaces</h2>
<p>In this section we will expand our analysis of linear systems to sketch a broad picture of linear algebra and its fundamental concepts. For a more thorough exposition, see <span class="citation" data-cites="strang_linear_2005">(<a href="references.html#ref-strang_linear_2005" role="doc-biblioref"><strong>strang_linear_2005?</strong></a>)</span>. Whenever we deal with more than one variable, they can be concisely written as a vector of multiple dimensions. We have seen that equations defining linear dynamical systems can be expressed as products of matrices and vectors. In order to understand how these systems operate and how to express their general solutions, we first need to be specific about the notions of linearity and how it affects vector spaces.</p>
<p>The nomenclature of linearity is derived from the functional description of a line in the plane. Any line passing through the origin can be described as a set of points that can be generated by multiplying them by a single scalar, called the slope, that is, it is generated by a linear transformation <span class="math inline">\(f(x) = ax\)</span>. This concept is generalized from dealing with scalars to vectors by the following definition:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>A <em>linear transformation</em> or <em>linear operator</em> is a mapping <span class="math inline">\(L\)</span> between two sets of vectors with the following properties:</p>
<ol type="1">
<li><p><em>(scalar multiplication)</em> <span class="math inline">\(L(c \vec v) = c L(\vec v)\)</span>; where <span class="math inline">\(c\)</span> is a scalar and <span class="math inline">\(\vec v\)</span> is a vector</p></li>
<li><p><em>(additive)</em> <span class="math inline">\(L(\vec v_1 + \vec v_2) = L(\vec v_1) + L(\vec v_2)\)</span>; where <span class="math inline">\(\vec v_1\)</span> and <span class="math inline">\(\vec v_2\)</span> are vectors</p></li>
</ol>
</div>
</div>
<p>We have already seen examples of linear transformations, in the form of matrices multiplying a vector. Matrix multiplication shares the linear property with scalar multiplication, but it transforms vectors to vectors, depending on the size of the matrix, and has more complicated properties. The notion of linearity then leads to the important idea of combining different vectors:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>A <em>linear combination</em> of <span class="math inline">\(n\)</span> vectors <span class="math inline">\(\{ \vec v_i \}\)</span> is a weighted sum of these vectors with any real numbers <span class="math inline">\(\{a_i\}\)</span>:</p>
<p><span class="math display">\[
a_1 \vec v_1+ a_2 \vec v_2... + a_n \vec v_n
\]</span></p>
</div>
</div>
<p>Linear combinations arise naturally from the notion of linearity, combining the additive property and the scalar multiplication property. Speaking intuitively, a linear combination of vectors produces a new vector that is related to the original set. Linear combinations give a simple way of generating new vectors, and thus invite the following definition for a collection of vectors closed under linear combinations:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>A <em>vector space</em> is a collection of vectors such that a linear combination of any <span class="math inline">\(n\)</span> vectors (with <span class="math inline">\(n \in \mathbb{N}\)</span>) is contained in the vector space.</p>
</div>
</div>
<p>The most common examples are the spaces of all real-valued vectors of dimension <span class="math inline">\(n\)</span>, which are denoted by <span class="math inline">\(\mathbb{R}^n\)</span>. For instance, <span class="math inline">\(\mathbb{R}^2\)</span> (pronounced “r two”) is the vector space of two dimensional real-valued vectors such as <span class="math inline">\((1,3)\)</span> and <span class="math inline">\((\pi, -\sqrt{17})\)</span>; similarly, <span class="math inline">\(\mathbb{R}^3\)</span> is the vector space consisting of three dimensional real-valued vectors such as <span class="math inline">\((0.1,0,-5.6432)\)</span>. By taking linear combinations of vectors in the plane, you can generate all the points in the usual Euclidean plane. The real number line can also be thought of as the vector space <span class="math inline">\(\mathbb{R}^1\)</span>.</p>
<p>How can we describe a vector space, without trying to list all of its elements? We know that one can generate an element by taking linear combinations of vectors. It turns out that it is possible to generate (or “span”) a vector space by taking linear combinations of a subset of its vectors. The challenge is to find a mininal subset of subset that is not redundant. In order to do this, we first introduce a new concept:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>A set of vectors <span class="math inline">\(\{ \vec v_i \}\)</span> is called <em>linearly independent</em> if the only linear combination involving them that equals the zero vector is if all the coefficients are zero.</p>
<p>(<span class="math inline">\(a_1 \vec v_1+ a_2 \vec v_2... + a_n \vec v_n = 0\)</span> only if <span class="math inline">\(a_i = 0\)</span> for all <span class="math inline">\(i\)</span>.)</p>
</div>
</div>
<p>In the familiar Euclidean spaces, e.g.&nbsp;<span class="math inline">\(\mathbb{R}^2\)</span>, linear independence has a geometric meaning: two vectors are linearly independent if the segments from the origin to the endpoint do not lie on the same line. But it can be shown that any set of three vectors in the plane is linearly <em>dependent</em>, because there are only two dimensions in the vector space. This brings us to the key definition of this section:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>A <em>basis</em> of a vector space is a linearly independent set of vectors that generate (or span) the vector space.</p>
</div>
</div>
<p>A vector space generally has many possible bases, as illustrated in figure . In the case of <span class="math inline">\(\mathbb{R}^2\)</span>, the canonical basis set is <span class="math inline">\(\{(1,0); (0,1)\}\)</span> which obviously generates any point on the plane and is linearly independent. But any two linearly independent vectors can generate any vector in the plane. For instance, the vector <span class="math inline">\(\vec r = (2,1)\)</span> can be represented as a linear combination of the two canonical vectors: <span class="math inline">\(\vec r = 2(1,0)+(0,1)\)</span>. Let us choose another basis set, by taking the vector itself as one of the basis vectors and leaving the second one from the canonical basis: <span class="math inline">\(\{(2,1); (0,1)\}\)</span> The same vector can be represented by a linear combination of these two vectors, with coefficients 1 and 0: <span class="math inline">\(\vec r = 1 (2,1) + 0(0,1)\)</span>. Since multiple bases are possible, we need a way of evaluating them and changing between them.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/2bases.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Two basis sets in the plane. Green arrows show the canonical Cartesian basis, while the red arrows correspond to the basis set <span class="math inline">\(\{ (3,1); (-2,1)\}\)</span>. Any point in the plane can be described in terms of both bases. <a href="http://www.math.hmc.edu/calculus/tutorials/changebasis/" class="uri">http://www.math.hmc.edu/calculus/tutorials/changebasis/</a></figcaption><p></p>
</figure>
</div>
<section id="inner-product-and-orthogonality" class="level3" data-number="11.2.1">
<h3 data-number="11.2.1" class="anchored" data-anchor-id="inner-product-and-orthogonality"><span class="header-section-number">11.2.1</span> inner product and orthogonality</h3>
<p>Not all basis sets are created equal. Continuing our geometric analogy, the canonical basis in <span class="math inline">\(\mathbb{R}^2\)</span> is related to the familiar Cartesian coordinates, with two orthogonal axes in the direction of the basis vectors <span class="math inline">\(\{(1,0); (0,1)\}\)</span> There are many other, non-orthogonal bases, like <span class="math inline">\(\{(2,1); (0,1)\}\)</span> above, but they are intuitively less economical, since one vector can make a contribution in the direction of the other. This means that a given vector can be represented in non-unique linear combinations with a non-orthogonal basis set. Thus, mathematicians prefer what are called orthogonal bases. In order to define orthogonality, we first introduce this key notion:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <em>inner product</em> of two vectors <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> is defined as the product of <span class="math inline">\(u\)</span> and the conjugate transpose <span class="math inline">\(v^*\)</span>: <span class="math inline">\(\langle u,v \rangle = uv^*\)</span>.</p>
</div>
</div>
<p>This is the general definition of inner product, rather than the more familiar notion of the dot product, which only applies to real vector spaces. One important difference that the inner product in this definition has a modified commutative property: <span class="math inline">\(\langle u,v \rangle = \overline{\langle v,u \rangle}\)</span> - meaning that switching the order of the inner product results in a complex conjugate of the result. For example: <span class="math inline">\(u=(-i, 5+i)\)</span> and <span class="math inline">\(v=(6, 4-3i)\)</span>. <span class="math inline">\(\langle u,v \rangle = -i*6 + (5+i)*(4+3i) = -6i+20-3+19i= 17+13i\)</span>, and <span class="math inline">\(\langle v,u \rangle = 6i+(4-3i)*(5-i) = 6i+20 -3- 15i-4i = 17 - 13i\)</span>.</p>
<p>The inner product is intimately tied to the geometric notion of direction of vectors in the Euclidean spaces. Let us consider a pair of vectors in <span class="math inline">\(\mathbb{R}^2\)</span> of unit length. If the two vectors have the same direction (are <em>colinear</em>), their inner product is equal to 1 or -1, depending on whether they are parallel or anti-parallel - for example, consider the cases of <span class="math inline">\(\langle (1,0), (1,0) \rangle = 1\)</span> and <span class="math inline">\(\langle (0,1),(0,-1) \rangle = -1\)</span>. If we rotate one vector relative to the other - for instance, keep the first vector fixed at <span class="math inline">\((1,0)\)</span> and let the other one be <span class="math inline">\((a,b)\)</span>, with the restriction that <span class="math inline">\(\sqrt{a^2+b^2} =1\)</span>, that is, it is of length 1. Their inner product is clearly equal to <span class="math inline">\(a\)</span>, which you should be able to convince yourself, is the cosine of the angle between the two vectors. With a little bit more work, you can demonstrate that this statement is true for any two unit vectors (those with length 1.)</p>
<p>What about vectors of arbitrary length? First, let us define the notion of length:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <em>length</em> (also known as the <em>norm</em>) of a vector <span class="math inline">\(u\)</span> is defined as the square root of the inner product with itself <span class="math inline">\(||u|| = \sqrt{\langle u,u \rangle} = \sqrt{uu^*}\)</span>.</p>
</div>
</div>
<p>For Euclidean vector spaces, this definition agrees with the familiar Euclidean distance, e.g.&nbsp;in <span class="math inline">\(\mathbb{R}^2\)</span>, for <span class="math inline">\(\vec v = (x,y)\)</span>, <span class="math inline">\(||\vec v|| =\sqrt{x^2+y^2}\)</span>.</p>
<p>Using the notion of length, or norm, vectors can be <em>normalized</em>, which means divided by the norm, creating a vector of length 1 (a.k.a. unit vector) with the same direction as the original. Since we know that the cosine of the angle <span class="math inline">\(\theta\)</span> between the vectors is the inner product of two unit vectors, we have the following relationship between any two vectors:</p>
<p><span class="math display">\[
\left\langle  \frac{\vec v}{||\vec v||} , \frac{\vec u}{||\vec u||} \right \rangle  = \cos(\theta) \Rightarrow \left\langle  \vec v, \vec u\right \rangle  =||\vec v|| ||\vec u||\cos(\theta)
\]</span></p>
<p>Finally, this leads us to the general statement about orthogonality in vector spaces, which is crucial not only for regular finite-dimensional vector spaces, but also in infinite-dimensional function spaces which we will see later:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>Two vectors are <em>orthogonal</em> if their inner product is zero.</p>
</div>
</div>
<p>Now that we know how to determine whether two vectors are orthogonal, we will call a basis set orthogonal if all pairs of vectors in it are orthogonal. Furthermore, it is typically convenient to require that all the vectors be of unit length, which can be accomplished by normalization. A basis set of mutually orthogonal unit vectors is called <em>orthonormal</em>. Typical examples are Cartesian coordinate vectors, such as <span class="math inline">\(\{ (1,0,0); (0,1,0); (0,0,1) \}\)</span> in <span class="math inline">\(\mathbb{R}^3\)</span>.</p>
</section>
<section id="projection-and-decomposition" class="level3" data-number="11.2.2">
<h3 data-number="11.2.2" class="anchored" data-anchor-id="projection-and-decomposition"><span class="header-section-number">11.2.2</span> projection and decomposition</h3>
<p>The basis set of a vector space serves as its defining structure, like a skeleton giving shape to the gelatinous multitude of vectors. Any element in a vector space can be described as a linear combination of the basis set. In the Euclidean plane, the vector <span class="math inline">\((3,4)\)</span> can be either thought of a collection of two numbers, or as a point with coordinates <span class="math inline">\(x=3\)</span> and <span class="math inline">\(y=4\)</span>. The latter concept refers to the linear combination of the two standard basis vectors with <em>coefficients</em> 3 and 4: <span class="math inline">\((3,4) = 3(1,0) + 4(0,1)\)</span>. The coefficients quantify the overlap of a vector <span class="math inline">\(\vec r\)</span> in question with each of the respective basis vectors. Geometrically, if a vector is parallel to a basis vector (of unit length,) then it can be represented as a multiple of the basis vector, and the coefficient will be equal to the length of the vector <span class="math inline">\(\vec r\)</span>. On the other hand, if a basis vector is orthogonal to the vector <span class="math inline">\(\vec r\)</span>, the corresponding coefficient will be 0.</p>
<p>The representation of an arbitrary vector of a vector space as a linear combination of a given basis set is called the <em>decomposition</em> of the vector in terms of the basis. However, we saw that many possible bases exist for any vector space. Even if we choose only orthonormal bases, there are many possibilities: for instance, in the space of real two dimensional vectors <span class="math inline">\(\mathbb{R}^2\)</span>, the standard basis <span class="math inline">\(\{(1,0); (0,1)\}\)</span> can be rotated to produce a different orthonormal basis, e.g.&nbsp;<span class="math inline">\(\{ (1/\sqrt 2, 1/\sqrt 2); \; (-1/\sqrt 2, 1/\sqrt 2) \}\)</span>.</p>
<p>Therefore, the choice of a basis determines how a given vector is represented. The decomposition of a vector in terms of a particular basis is very useful in high-dimensional spaces, where a clever choice of a basis can allow a description of a vector in terms of contributions of only a few basis vectors. The vector may then be represented, given the basis set, with a few coefficients of the relevant basis vectors.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/vec_proj.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Projection of vector <span class="math inline">\(A\)</span> onto vector <span class="math inline">\(B\)</span>, with angle <span class="math inline">\(\theta\)</span> between their directions. <a href="http://en.wikipedia.org/wiki/Vector_projection" class="uri">http://en.wikipedia.org/wiki/Vector_projection</a></figcaption><p></p>
</figure>
</div>
<p>To obtain the coefficients of the basis vectors in a decomposition of a vector <span class="math inline">\(\vec r\)</span>, we need to perform what is termed a <em>projection</em> of the vector onto the basis vectors. Think of shining a light perpendicular to the basis vector, and measuring the length of the shadow cast by the vector <span class="math inline">\(\vec r\)</span> onto <span class="math inline">\(\vec v_i\)</span>. If the vectors are parallel, the shadow is equal to the length of <span class="math inline">\(\vec r\)</span>; if they are orthogonal, the shadow is nonexistent. To find the length of the shadow, use the inner product of <span class="math inline">\(\vec r\)</span> and <span class="math inline">\(\vec v\)</span>, which as you recall corresponds to the cosine of the angle between the two vectors multiplied by their norms: <span class="math inline">\(\left\langle \vec r, \vec v\right \rangle=||\vec r|| ||\vec v||\cos(\theta)\)</span> (see figure .) We do not care about the length of the vector <span class="math inline">\(\vec v\)</span> we are projecting onto, thus we divide the inner by product by the square norm of <span class="math inline">\(\vec v\)</span>, and then multiply the vector <span class="math inline">\(\vec v\)</span> by this projection coefficient:</p>
<p><span class="math display">\[
Proj(\vec r ; \vec v) = \frac{\langle \vec r, \vec v \rangle} {\langle \vec v , \vec v \rangle } \vec v = \frac{ \langle \vec r, \vec v \rangle} {|| \vec v ||^2} \vec v = \frac{||\vec r|| \cos(\theta)} {||\vec v ||}\vec v
\]</span></p>
<p>This formula gives the projection of the vector <span class="math inline">\(\vec r\)</span> onto <span class="math inline">\(\vec v\)</span>, the result is a new vector in the direction of <span class="math inline">\(\vec v\)</span>, with the scalar coefficient <span class="math inline">\(a = \ \langle \vec r , \vec v \rangle /|| \vec v ||^2\)</span>.</p>
<p><strong>Example:</strong> Let us decompose the vector <span class="math inline">\((3,4)\)</span> in a nonstandard basis, e.g.&nbsp;the canonical basis rotated by <span class="math inline">\(45^\circ\)</span>: <span class="math inline">\(\{ (1/\sqrt 2, 1/\sqrt 2); \; (-1/\sqrt 2, 1/\sqrt 2) \}\)</span>. Use the projection formula above to obtain the coefficients of decomposition. The length of both basis vectors is 1, so the denominator is unity:</p>
<p><span class="math display">\[
a_1 = (\frac{1}{\sqrt 2}, \frac{1}{\sqrt 2}) \cdot (3,4) = \frac{7}{\sqrt 2}; \; a_2 = (-\frac{1}{\sqrt 2}, \frac{1}{\sqrt 2}) \cdot (3,4) = \frac{1}{\sqrt 2}
\]</span></p>
<p>Therefore, we have the following decomposition:</p>
<p><span class="math display">\[
(3,4) = \frac{7}{\sqrt 2} (\frac{1}{\sqrt 2}, \frac{1}{\sqrt 2})  + \frac{1}{\sqrt 2} (-\frac{1}{\sqrt 2}, \frac{1}{\sqrt 2})
\]</span></p>
<p>Why go through this rigmarole of expressing one vector in terms of <span class="math inline">\(N\)</span> others? A decomposition in terms of a basis is necessary to express a vector in any vector space, as the basis serves as a coordinate system and the coefficients as coordinates of the point designated by the vector. Even in the regular Euclidean space, a vector (e.g.&nbsp;<span class="math inline">\((3,4)\)</span>) requires an implicit basis set in order to make it meaningful. If we choose a different basis set, the formula above allows us to express the vector in a new basis. As mentioned above, in higher-dimensional vector spaces a good choice of basis is important because it can greatly simplify calculations.</p>
</section>
<section id="general-solution-of-linear-odes" class="level3" data-number="11.2.3">
<h3 data-number="11.2.3" class="anchored" data-anchor-id="general-solution-of-linear-odes"><span class="header-section-number">11.2.3</span> general solution of linear ODEs</h3>
<p>One very important application of vector decomposition simplifies the solution of linear dynamical systems. Any linear system can be defined in terms of a matrix <span class="math inline">\(A\)</span>, and we saw in Chapter 6 that the solution can be expressed in terms of its eigenvectors. The new concept is that the set of eigenvectors of a matrix forms a basis set for the vector space, provided the matrix is nonsingular. For instance, for a (2x2) matrix <span class="math inline">\(A\)</span> with eigenvectors <span class="math inline">\(\vec v_1, \vec v_2\)</span> and eigenvalues <span class="math inline">\(\lambda_1,\lambda_2\)</span>, the simplest way to compute its effect on a vector <span class="math inline">\(\vec u\)</span> is to decompose it in the basis of the two eigenvectors: <span class="math inline">\(\vec u = c_1\vec v_1 + c_2\vec v_2\)</span>, and then apply the matrix to the two eigenvectors, using the linear property:</p>
<p><span class="math display">\[
A\vec u = A c_1\vec v_1 + A c_2\vec v_2 = c_1\lambda_1\vec v_1 + c_2\lambda_2\vec v_2
\]</span></p>
<p>This gives us a simplification of a matrix multiplication to two scalar multiplications of the two eigenvectors by the eigenvalues <span class="math inline">\(\lambda_i\)</span> and the coefficients <span class="math inline">\(c_i\)</span>. What is needed is knowledge of the eigenvalues and the eigenvectors, and the coefficients. We have already seen that finding eigenvectors and eigenvalues is a difficult problem, best left to computers. But for a given linear dynamical system, it only needs to be done once. Then, given any initial vector <span class="math inline">\(\vec u\)</span>, one can decompose it in terms of the normalized eigenvectors, with <span class="math inline">\(c_i = \langle \vec u, \vec v_i \rangle\)</span>. Then we can obtain the general solution for the linear dynamical systems, as a linear combination of the eigenvectors multiplied by exponentials with rates <span class="math inline">\(\lambda_i\)</span>:</p>
<p><span class="math display">\[
\frac{d \vec x}{dt} = A \vec x; \; \vec x(0) = \vec x_0 \Rightarrow \vec x(t)= \sum_i c_i e^{\lambda_i t} \vec v_i
\]</span></p>
</section>
</section>
<section id="computational-normal-mode-calculations" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="computational-normal-mode-calculations"><span class="header-section-number">11.3</span> Computational: normal mode calculations</h2>
<section id="harmonic-analysis-of-coupled-oscillators" class="level3" data-number="11.3.1">
<h3 data-number="11.3.1" class="anchored" data-anchor-id="harmonic-analysis-of-coupled-oscillators"><span class="header-section-number">11.3.1</span> harmonic analysis of coupled oscillators</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/coupled_springs.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Illustration of a model of two coupled springs attached to a wall. <a href="http://en.wikipedia.org/wiki/Normal_mode" class="uri">http://en.wikipedia.org/wiki/Normal_mode</a></figcaption><p></p>
</figure>
</div>
<p>In the modeling section we saw a model describing the dynamics of two objects connected by a spring <span class="citation" data-cites="fig:coupled_springs">(<a href="references.html#ref-fig:coupled_springs" role="doc-biblioref"><strong>fig:coupled_springs?</strong></a>)</span>. We used Hookean potentials to describe the interactions between two masses, which correspond to linear forces. This results in the equations of motion that are a linear system of second-order ODEs. Before we have only seen systems of first-order ODEs, but we can make use of linear algebra to find the solutions. We take the matrix of the system,</p>
<p><span class="math display">\[
A = \frac{k}{m}\left(\begin{array}{cc}-1 &amp; 1 \\1 &amp; -1\end{array}\right)
\]</span></p>
<p>This matrix is known as the <em>Hessian</em> matrix, which means the matrix of second derivatives of the potential function. The eigenvalues of this particular Hessian matrix are 0 and <span class="math inline">\(-2k/m\)</span>. With a little bit of work, we can find the corresponding eigenvectors: <span class="math inline">\(v_1 = (1,1)\)</span> for the 0 eigenvalue and <span class="math inline">\(v_2 = (1,-1)\)</span> for the -2 eigenvalue. Now consider how the solutions behave in terms of these basis vectors. If the initial condition corresponds to the vector <span class="math inline">\(v_2\)</span>, then the ODE becomes, in matrix and vector form:</p>
<p><span class="math display">\[
\ddot v_2 = A v_2 = -2 \frac{k}{m} v_2
\]</span></p>
<p>We know from previous examples that the solutions of this equation (assuming <span class="math inline">\(k,m &gt;0\)</span>) are purely oscillatory, with frequency <span class="math inline">\(\sqrt{2k/m}\)</span>. Note that unlike in the previous first-order ODE examples, negative eigenvalues mean <em>oscillatory</em> behavior, rather than exponential decay. The form of the eigenvector <span class="math inline">\((1,-1)\)</span> indicates that two masses will oscillate with opposite phases: when <span class="math inline">\(x\)</span> is moving right, <span class="math inline">\(y\)</span> is moving left, and vice versa.</p>
<p>The eigenvalue of 0 is a special case. We can say that it indicated an oscillation frequency of 0, since the second derivative equals 0, which implies a constant velocity. This is a called a <em>translational</em> motion, and the form of the eigenvector <span class="math inline">\((1,1)\)</span> indicates that <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> move in concert, either left or right.</p>
<p>The eigenvectors of the Hessian of a system of coupled linear oscillators are called <em>normal modes</em>. Each one describes a <em>collective vibrational motion</em> of a particular frequency, in which the particles participate with relative coefficients given by the normal mode. The corresponding eigenvalues correspond to the squared frequencies of the collective oscillation described by the normal mode.</p>
</section>
<section id="normal-mode-calculations" class="level3" data-number="11.3.2">
<h3 data-number="11.3.2" class="anchored" data-anchor-id="normal-mode-calculations"><span class="header-section-number">11.3.2</span> normal mode calculations</h3>
<p>In order to perform normal mode calculations, one needs two things: the Hessian matrix and the ability to diagonalize it (find its eigenvalues and eigenvectors.) Let us consider that we have a system of coupled Hookean potentials, each “spring” connecting nodes <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> with its own force constant <span class="math inline">\(k_{ij}\)</span>. Note that Hookean potentials, so if node <span class="math inline">\(i\)</span> is connected to mode <span class="math inline">\(j\)</span>, then node <span class="math inline">\(j\)</span> is connected to mode <span class="math inline">\(i\)</span> with the same force constant. Then we construct the Hessian matrix as follows:</p>
<p>obtain list of 3D coordinates for <span class="math inline">\(N\)</span> nodes <span class="math inline">\(X_i =(x_i,y_i, z_i)\)</span> set cutoff distance <span class="math inline">\(R\)</span> define a distance function <span class="math inline">\(dist(X_i, X_j)\)</span> (returns distance between two 3-dimensional vectors) pre-allocate Hessian matrix <span class="math inline">\(H\)</span> (<span class="math inline">\(N\)</span> by <span class="math inline">\(N\)</span>) with 0s <span class="math inline">\(H[i,j] \gets -k\)</span> <span class="math inline">\(H[j,i] \gets -k\)</span> <span class="math inline">\(H[j,j] \gets H[j,j] + k\)</span></p>
<p>Consider three nodes connected as a linear chain, with node 1 connected to node 2 with force constant <span class="math inline">\(k_{1}\)</span>, and node 2 connected to node 3 with force constant <span class="math inline">\(k_2\)</span>, the Hessian matrix is:</p>
<p><span class="math display">\[
H = \left(\begin{array}{ccc}k_1 &amp; -k_1 &amp; 0 \\-k_1 &amp; k_1+k_2 &amp; -k_2 \\0 &amp; -k_2 &amp; k_2\end{array}\right)
\]</span></p>
<p>Now that we have constructed the Hessian matrix, we need to diagonalize it to find the normal modes. We will not describe the algorithms to find the eigenvalues and eigenvectors of matrices, as those deserve their own chapter, but this topic is well addressed in <span class="citation" data-cites="press_numerical_2007">(<a href="references.html#ref-press_numerical_2007" role="doc-biblioref"><strong>press_numerical_2007?</strong></a>)</span>. Let us stipulate that one can use a function that will produce a set of eigenvectors, sorted by the magnitude of the corresponding eigenvalues.</p>
<p>For the system of three nodes described above, let both springs have the same force constant of 1(<span class="math inline">\(k_1=k_2 = 1\)</span>.) Then the system has the following eigenvectors and eigenvalues:</p>
<p><span class="math display">\[
\vec v_1 = \left(\begin{array}{c} 1\\  1 \\1 \end{array}\right) \;  \lambda_1 = 0 ; \; \vec v_2 = \left(\begin{array}{c} -1\\  0 \\1 \end{array}\right) \;  \lambda_2 = 1 ; \; \vec v_3 = \left(\begin{array}{c} 1\\  -2 \\1 \end{array}\right) \;  \lambda_3 = 3
\]</span></p>
<p>This demonstrated that a linear chain of three oscillators that are not attached to any other object has three normal modes of different frequencies. The first mode has zero frequency, which is known as a <em>rigid-body</em> mode, in which the entire system moves together, without changes in relative distances. The second mode has frequency 1, and in it the two end nodes move in opposite directions of each other. The third mode has frequency <span class="math inline">\(\sqrt{3}\)</span>, and in it the end points move in the same direction, while the middle node moves in the opposite direction with twice the amplitude. This analysis predicts that all motions of the three nodes can be described in terms of the three normal modes.</p>
</section>
</section>
<section id="normal-mode-analysis-of-biomolecular-structures" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="normal-mode-analysis-of-biomolecular-structures"><span class="header-section-number">11.4</span> Normal mode analysis of biomolecular structures</h2>
<section id="biomolecular-structures-as-elastic-solids" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1" class="anchored" data-anchor-id="biomolecular-structures-as-elastic-solids"><span class="header-section-number">11.4.1</span> biomolecular structures as elastic solids</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/prot_landscape.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Cartoon depiction of the potential function of a protein, reduced to two variables. Vertical dimension indicates relative energy level of different conformations. The sharp well in blue is the native conformation. http://www.btinternet.com/~martin.chaplin/protein2.html</figcaption><p></p>
</figure>
</div>
<p>Proteins inside cells fold into exquisitely precise structures, which enable them to perform a tremendous variety of functions, from catalyzing biochemical reactions to binding signaling molecules. The location of amino acids residues and all the atoms, is called the protein’s structure. Determining the structure of a protein is laborious, although thanks to technological advances structural determination is less difficult than in the past. The knowledge of a protein’s structure provided a great deal of important information to biochemists, for instance the location of the catalytic active side. However, it does not tell the whole story of how the protein functions.</p>
<p>The structures of proteins and other biomolecules are not static, but instead fluctuate around the most energetically favorable conformation. These fluctuations are cause by the jiggling of the surrounding molecules, such as waters due to the thermal motion at the molecular level. A protein molecule can be thought of as a system with a potential, shaped by the interactions between all the atoms in the molecule, and with the surrounding solvent. The variables of the system are the positions of all the atoms, which means that the system has thousands or tens of thousands of variables. Figure <span class="citation" data-cites="fig:prot_land">(<a href="references.html#ref-fig:prot_land" role="doc-biblioref"><strong>fig:prot_land?</strong></a>)</span> shows a cartoon of the potential energy function of a complex molecule. It shows a sharp well with the preferred folded state at the minimum. Thermal noise adds random kinetic energy to the system, causing the conformations to jiggle in the well, and occasionally causing major conformational changes or even unfolding.</p>
<p>Normal modes are used to study the flexibility of molecular structures. The basic assumption is that the molecules behave as coupled harmonic oscillators, with each atom connected to other atoms by harmonic potentials. This assumption makes physical sense at the bottom of the potential well, near the native conformation, where the potential must have close to quadratic shape, and therefore the restoring forces are nearly linear with displacement.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/calm_gnm.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Harmonic potential model of the protein calmodulin. Green indicates the backbone of the molecule, maroon lines indicated harmonic interactions between residues.</figcaption><p></p>
</figure>
</div>
<p>Various models exist for defining the connections in protein structure between different particles, which could be atoms or amino acid residues, or even blocks of many residues. The connections may be based of physical chemical forces, such as chemical bonds, van der Waals forces, and electrostatic interactions, or may be based on a simple model where parts of the protein in proximity are assumed to interact as if bound by a linear spring. These interactions yield a matrix equivalent to the one we saw for two coupled oscillators, known as Hessian matrix. Figure [fig:calm_gnm] shows the harmonic potentials used to model the structural dynamics of the protein calmodulin. Connections were chosen based on distance proximity between residues. <span class="citation" data-cites="cui_normal_2005">(<a href="references.html#ref-cui_normal_2005" role="doc-biblioref"><strong>cui_normal_2005?</strong></a>)</span>.</p>
</section>
<section id="sorting-normal-modes-by-frequency" class="level3" data-number="11.4.2">
<h3 data-number="11.4.2" class="anchored" data-anchor-id="sorting-normal-modes-by-frequency"><span class="header-section-number">11.4.2</span> sorting normal modes by frequency</h3>
<p>The normal modes and the corresponding frequencies are determined by computationally finding the eigenvectors and eigenvalues of the Hessian matrix. For practical purposes, the most interesting modes are those with lowest (but nonzero) frequencies, because they correspond to the slowest and most global collective motions, as opposed to high-frequency vibrations, which are restricted both in amplitude and in scope. Intuitively, the lowest frequency modes correspond to the shallowest directions in the potential energy well. Given a reasonable amount of thermal noise, the protein structure is most likely to be deformed along the shallow directions, instead of climbing up the steep directions.</p>
<p>The utility of normal mode analysis of biological molecules lies in obtaining the preferred modes of flexibility from a static structure, which allows biochemists to better understand the mechanism of the molecular function. For instance, in studying the mechanism of opening or closing of an enzyme binding site, normal modes can generate a hypothesis about the intermediate conformations, and help predict which residues play a key role. Figure [fig:calm_nma] shows the directions of the lowest frequency mode of calmodulin, which undergoes a large conformational change in response to binding of calcium ions. The arrows show the extent of involvement of each amino acid residue, as well as the direction of preferred fluctuations. To summarize, changing the coordinate system from individual positions to collective normal modes of motion simplifies the systems and generates predictions relevant for understanding the function of biomolecules.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/calm_nma.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Lowest frequency mode predicted from normal mode analysis of calmodulin. Arrows indicate the direction and magnitude of flexibility associated with each residue.</figcaption><p></p>
</figure>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch10_phase_portraits.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Phase portraits in Python</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>